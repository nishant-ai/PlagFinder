{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "263b4a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frequency\n",
      "       frequency_scraped  frequency_test  frequency_match\n",
      "count                1.0             1.0              1.0\n",
      "mean                 1.0             0.0              0.0\n",
      "std                  NaN             NaN              NaN\n",
      "min                  1.0             0.0              0.0\n",
      "25%                  1.0             0.0              0.0\n",
      "50%                  1.0             0.0              0.0\n",
      "75%                  1.0             0.0              0.0\n",
      "max                  1.0             0.0              0.0\n",
      "Data-Pair Frequency\n",
      "       frequency_scraped frequency_test frequency_match\n",
      "count                  0              0               0\n",
      "unique                 0              0               0\n",
      "top                  NaN            NaN             NaN\n",
      "freq                 NaN            NaN             NaN\n",
      "Data-Trigram Frequency\n",
      "       frequency_scraped frequency_test frequency_match\n",
      "count                  0              0               0\n",
      "unique                 0              0               0\n",
      "top                  NaN            NaN             NaN\n",
      "freq                 NaN            NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "punctuation += \"’\"\n",
    "\n",
    "def openFile(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def word_frequency(text):\n",
    "    paragraph = text\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(paragraph)\n",
    "    filtered_tokens = [word for word in word_tokens if (not word.lower() in stop_words) and (not word.lower() in punctuation)]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_tokens =[lemmatizer.lemmatize(t) for t in filtered_tokens]\n",
    "\n",
    "    counted = Counter(filtered_tokens)\n",
    "    counted_2= Counter(ngrams(filtered_tokens,2))\n",
    "    counted_3= Counter(ngrams(filtered_tokens,3))\n",
    "\n",
    "    word_freq = pd.DataFrame(counted.items(),columns=['word','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    word_pairs = pd.DataFrame(counted_2.items(),columns=['word','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    trigrams = pd.DataFrame(counted_3.items(),columns=['word','frequency']).sort_values(by='frequency',ascending=False)\n",
    "    word_freq.fillna(0)\n",
    "    word_pairs.fillna(0)\n",
    "    trigrams.fillna(0)\n",
    "    \n",
    "    return word_freq, word_pairs, trigrams\n",
    "\n",
    "def frequencyMatch(df_scraped , df_test):\n",
    "    merged = df_scraped.set_index(\"word\").join(df_test.set_index(\"word\"), lsuffix='_scraped', rsuffix='_test')\n",
    "    merged = merged.fillna(0)\n",
    "    frequency_match = merged.frequency_test*100 / merged.frequency_scraped\n",
    "    merged['frequency_match'] = frequency_match\n",
    "    merged.frequency_match = np.where(merged.frequency_match < 0, 0, merged.frequency_match)\n",
    "    return merged.describe()\n",
    "\n",
    "\n",
    "df_s_1, df_s_2, df_s_3 = word_frequency('scraped_dat_1.txt')\n",
    "df_t_1, df_t_2, df_t_3 = word_frequency('scraped_dat_2.txt')\n",
    "\n",
    "print(\"Data Frequency\")\n",
    "ans = frequencyMatch(df_s_1, df_t_1)\n",
    "print(ans)\n",
    "\n",
    "print(\"Data-Pair Frequency\")\n",
    "ans2 = frequencyMatch(df_s_2, df_t_2)\n",
    "print(ans2)\n",
    "\n",
    "print(\"Data-Trigram Frequency\")\n",
    "ans3 = frequencyMatch(df_s_3, df_t_3)\n",
    "print(ans3)\n",
    "\n",
    "def stringTokenize(filename):\n",
    "    s = openFile(filename)\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    stringTokens = sent_tokenize(s)\n",
    "    return stringTokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1e097c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_match(testTokenSet, scrapeTokenSet):\n",
    "    matchMap = []\n",
    "    for test_token in testTokenSet:\n",
    "        word_freq_test, pair_freq_test, trigram_freq_test = word_frequency(test_token)\n",
    "        for scrape_token in scrapeTokenSet:\n",
    "            word_freq_scrape, pair_freq_scrape, trigram_freq_scrape = word_frequency(scrape_token)\n",
    "            match_table = frequencyMatch(word_freq_test, word_freq_scrape)\n",
    "            match_mean = match_table.frequency_match[1] # mean\n",
    "            if match_mean == 0:\n",
    "                continue\n",
    "            matchMap.append({\n",
    "                'test_token' : test_token,\n",
    "                'scrape_token' : scrape_token,\n",
    "                'similarity' : match_mean\n",
    "            })\n",
    "    matchMap = pd.DataFrame(matchMap)\n",
    "    return matchMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04057b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sentence_match(stringTokenize('scraped_dat_1.txt'), stringTokenize('scraped_dat_1.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "092fe79e",
   "metadata": {},
   "source": [
    "FAILED ALGO DOWN HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "56bf39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_match_00(testTokenSet, scrapeTokenSet):\n",
    "    matchMap = []\n",
    "    for test in testTokenSet:\n",
    "        for scrape in scrapeTokenSet:\n",
    "            test_tokens = set(word_tokenize(test))\n",
    "            scrape_tokens = set(word_tokenize(scrape))\n",
    "            test_int_scrape = len(test_tokens.intersection(scrape_tokens))\n",
    "            scrape_size = len(scrape_tokens)\n",
    "            match_percent=(test_int_scrape*100)/scrape_size\n",
    "            if match_percent == 0:\n",
    "                continue\n",
    "            matchMap.append({\n",
    "                'test_token' : test,\n",
    "                'scrape_token' : scrape,\n",
    "                'similarity' : match_percent\n",
    "            })\n",
    "    matchMap = pd.DataFrame(matchMap)\n",
    "    return matchMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9d3f209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sentence_match_00(stringTokenize('scraped_dat_1.txt'), stringTokenize('scraped_dat_1.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ab262dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_token</th>\n",
       "      <th>scrape_token</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our editors will review what you’ve submitted ...</td>\n",
       "      <td>Our editors will review what you’ve submitted ...</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our editors will review what you’ve submitted ...</td>\n",
       "      <td>Although there are no AIs that can perform the...</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our editors will review what you’ve submitted ...</td>\n",
       "      <td>Machine learning is the method to train a comp...</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our editors will review what you’ve submitted ...</td>\n",
       "      <td>Machine learning helps a computer to achieve a...</td>\n",
       "      <td>48.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our editors will review what you’ve submitted ...</td>\n",
       "      <td>The term is frequently applied to the project ...</td>\n",
       "      <td>25.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>For example, a program that learns the past te...</td>\n",
       "      <td>The program might then store the solution with...</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>For example, a program that learns the past te...</td>\n",
       "      <td>This simple memorizing of individual items and...</td>\n",
       "      <td>42.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>For example, a program that learns the past te...</td>\n",
       "      <td>More challenging is the problem of implementin...</td>\n",
       "      <td>36.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>For example, a program that learns the past te...</td>\n",
       "      <td>Generalization involves applying past experien...</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>For example, a program that learns the past te...</td>\n",
       "      <td>For example, a program that learns the past te...</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            test_token  \\\n",
       "0    Our editors will review what you’ve submitted ...   \n",
       "1    Our editors will review what you’ve submitted ...   \n",
       "2    Our editors will review what you’ve submitted ...   \n",
       "3    Our editors will review what you’ve submitted ...   \n",
       "4    Our editors will review what you’ve submitted ...   \n",
       "..                                                 ...   \n",
       "430  For example, a program that learns the past te...   \n",
       "431  For example, a program that learns the past te...   \n",
       "432  For example, a program that learns the past te...   \n",
       "433  For example, a program that learns the past te...   \n",
       "434  For example, a program that learns the past te...   \n",
       "\n",
       "                                          scrape_token  similarity  \n",
       "0    Our editors will review what you’ve submitted ...  100.000000  \n",
       "1    Although there are no AIs that can perform the...   33.333333  \n",
       "2    Machine learning is the method to train a comp...   28.571429  \n",
       "3    Machine learning helps a computer to achieve a...   48.275862  \n",
       "4    The term is frequently applied to the project ...   25.806452  \n",
       "..                                                 ...         ...  \n",
       "430  The program might then store the solution with...   35.000000  \n",
       "431  This simple memorizing of individual items and...   42.105263  \n",
       "432  More challenging is the problem of implementin...   36.363636  \n",
       "433  Generalization involves applying past experien...   40.000000  \n",
       "434  For example, a program that learns the past te...  100.000000  \n",
       "\n",
       "[435 rows x 3 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6c2a1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAILED ALGO ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7f8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4105f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd487e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4c690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ab5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6075961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c4976a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3897b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e036b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d3cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93aebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c3a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7bbf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e78104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8e807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaecf46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da1a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa023ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dcff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea6ee29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3eb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e5a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5efc31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d35baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb63ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd478fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
