Sign inLuthfi RamadhanJan 5, 2021·5 min readThe human brain consists of billions of neurons connected to each other and each neuron is passing a signal to another through the connection. This causes humans to have a specific action to be performed. For example, you want to reach your pocket to grab your phone, then there will be a signal that being sent to your brain and passed through these billions of neurons connection. Then the neurons that are responsible for this task will fire up and send back the signal to move your hand and grab your phone.The human brain has an extremely complex structure, judging from the number of its neuron, its processing speed, and its efficiency are proof that human is a perfect living thing. At birth, a baby’s brain contains 100 billion neurons. During the early stage of life, the brain eliminates connections that are seldom or never used, which is a normal part of brain development.A neuron is a cell in the human brain which responsible for receiving sensory input from the external world, sending signals to human muscles, and transforming and relaying the electrical signals at every step in between.A neuron consists of 3 main parts namely the dendrite, axon, and cell body. The dendrite is where a neuron receives input from other neurons. The axon is the output of a neuron it transmits the signal to other neurons. The cell body contains a nucleus and genetic material, which controls the cell’s activities.Neurons communicate with each other by sending signals, called neurotransmitters, across a narrow space, called a synapse, between the axons of the sender neuron and dendrites of the receiver neuron.The purpose of an artificial neural network is to mimic how the human brain works with the hope that we can build a machine that behaves like a human. An artificial neuron is the core building block of an artificial neural network.The structure of an artificial neuron is very similar to a biological neuron, it consists of 3 main parts, weight and bias as a dendrite denoted by w and b respectively, output as an axon denoted by y, and activation function as a cell body (nucleus) denoted by f(x). The x is the input signals received by the dendrite.In artificial neurons, input and weight are represented as a vector while bias is represented as a scalar. Artificial neuron processes input signals by performing a dot product between the input vector and the weight vector, add the bias, then apply an activation function, and finally propagates the result to other neurons.What is this activation function thing we have talked about a moment ago? why is the activation function important? what is the role of the activation function that makes it so important?Activation functions are an essential part we should not underestimate, It’s a function that an artificial neuron uses to get the output of a neuron, it is also known as Transfer Function. The result of the dot product between weight and input plus bias is in the range of -inf and +inf, activation function aims to map the result into a certain range depending upon the function.There are many activation functions out there, but the most important is the sigmoid activation function. It often used as activation in the output layer for binary classification tasks. Sigmoid bounds the result in the range of 0 until 1, it represents the probability of x whether x belongs to class 1 or 0. Sigmoid makes a decision by thresholding the result, if the result is ≥ 0.5 then x is classified as 1 otherwise, x is classified as 0.An artificial neural network is a bunch of artificial neurons interconnected to each other. Artificial neural networks (ANNs) learn to solve problems like a human brain. They process information by filtering it through densely connected artificial neurons. Each connection between neurons can transmit the signal to one another.The neurons are structured into several sequential layers. Each neuron of a layer is connected to every neuron on the previous and the next layer. Every layer received input from the previous layer, processes it, and feeds it to the next layer. The first layer is called the input layer, it takes input and feeds them to the next layer. It doesn't have any weight, bias, and activation function. The last layer is called the output layer, it makes decisions about the data that is being fed. In between these two layers is called the hidden layer. This is where the computation takes place. We can stack hidden layers as many as we want to, but there will be a trade-off with the computation speed.An artificial neural network works by processing the input signals through the whole network and obtain the result on the output layer. This is also known as feedforward. The result then compared with the ground truth using a function. This function is called the loss function, it is a measurement that tells us how well our neural network models the data. The higher the loss, the worse the model.An artificial neural network learns by nudging it’s weight and bias so that it has a better prediction. The most popular algorithm is gradient descent, it is an iterative process that aims to minimize the loss function. In other words, it tries to find weights and biases in which if we use those weights and biases, the loss function will be minimum.An artificial neural network is an algorithm that tries to mimic how human brains work. It processes information by filtering it through densely connected artificial neurons. It learns by finding weights and biases in which the loss function will be minimum.extension.umaine.edutowardsdatascience.comtowardsdatascience.comComputer Science Student at University of Indonesia. Reach me at https://www.linkedin.com/in/luthfi-ramadhan/173 1173 173 1Your home for data science. A Medium publication sharing concepts, ideas and codes.